{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Domain Understanding: Classification"
      ],
      "metadata": {
        "id": "nygJ_7SktKDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tImXI-qpzzyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame=pd.read_csv('/content/Monkeypox Coursework Dataset.csv')"
      ],
      "metadata": {
        "id": "qokYFP-CzzuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.head()"
      ],
      "metadata": {
        "id": "Qw83csXOzzqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNfvpmvv0C9N",
        "outputId": "216f6cc1-ec70-48e2-a479-054f1e329571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.describe()"
      ],
      "metadata": {
        "id": "RIXL4KLQ0FN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.dtypes\n"
      ],
      "metadata": {
        "id": "2J1iKhI10KhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.isnull().sum()"
      ],
      "metadata": {
        "id": "XkzL4J1J0Kcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = data_frame.dropna()\n",
        "data_frame"
      ],
      "metadata": {
        "id": "2vx7zQ0Q0KX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.isnull().sum()"
      ],
      "metadata": {
        "id": "i_AogCm20WZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.drop({'Test ID', 'Systemic Illness', 'Month of Birth', 'Health Insurance', 'Home ownership'},axis = 1)\n",
        "data_frame.drop"
      ],
      "metadata": {
        "id": "hhtPB7LE0WWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class_counts = data_frame['MPOX PCR Result'].value_counts()\n",
        "\n",
        "\n",
        "plt.bar(class_counts.index, class_counts.values, color=['skyblue', 'orange', 'green'])\n",
        "\n",
        "\n",
        "plt.title('Distribution of Class Variable')\n",
        "plt.xlabel('MPOX PCR Result')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jW79dtPW0WSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data prep"
      ],
      "metadata": {
        "id": "omZit4ax0oKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word2number"
      ],
      "metadata": {
        "id": "C38LsAZajZgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from word2number import w2n\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def prepare_data(datasave):\n",
        "    # Drop rows with missing values\n",
        "    df = datasave.dropna()\n",
        "    print('Dropping rows with missing values')\n",
        "    # Unique values in the 'Age' column\n",
        "    print('Clean and transform Features')\n",
        "    unique_values = df['Age'].unique()\n",
        "    print(\"Unique values in the 'Age' Feature:\")\n",
        "    print(unique_values)\n",
        "\n",
        "    # Cleaning and Transforming Age Feature and values\n",
        "    def transform_age(value):\n",
        "        values_to_remove = ['0', '181', '-23', '150']\n",
        "        if value in values_to_remove:\n",
        "            return np.nan\n",
        "        else:\n",
        "            try:\n",
        "                return float(value)\n",
        "            except ValueError:\n",
        "                return w2n.word_to_num(value)\n",
        "\n",
        "    df['Age'] = df['Age'].apply(transform_age)\n",
        "    dfcleaned = df.dropna(subset=['Age'])\n",
        "    print('Cleaning Age Feature and Converted to Float')\n",
        "    unique_values = dfcleaned['Age'].unique()\n",
        "    print(\"Unique values in the 'Age' Feature after cleaning:\")\n",
        "    print(unique_values)\n",
        "\n",
        "    unique_values = dfcleaned['Oral Lesions'].unique()\n",
        "    print(\"Unique values in the 'Oral Lesions' Feature:\")\n",
        "    print(unique_values)\n",
        "\n",
        "    # Cleaning and transforming Oral Lesions Feature and values\n",
        "    print('Cleaning and transforming Oral Lesions Feature and values')\n",
        "    dfcleaned['Oral Lesions'] = dfcleaned['Oral Lesions'].replace({'YES': 1, 'No': 0})\n",
        "    dfcleaned['Oral Lesions'] = dfcleaned['Oral Lesions'].astype(float)\n",
        "    print(\"Unique values in the 'Oral Lesions' Feature after cleaning:\")\n",
        "    print( dfcleaned['Oral Lesions'].unique())\n",
        "\n",
        "\n",
        "    # Transforming target variable into 0 and 1\n",
        "    dfcleaned['MPOX PCR Result'] = dfcleaned['MPOX PCR Result'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
        "    print('Transforming target variable into 0 and 1')\n",
        "\n",
        "    # Splitting into features (X) and target variable (y)\n",
        "\n",
        "    X = dfcleaned.drop(columns=['MPOX PCR Result'], axis=1)\n",
        "    y = dfcleaned['MPOX PCR Result']\n",
        "    print('Splitting into features (X) and target variable (y)')\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "    print('Train-Test split')\n",
        "    print('X_train before normalizing')\n",
        "    print(X_train)\n",
        "    # Normalize count columns using MinMaxScaler\n",
        "    count_columns = ['Red blood cells count', 'White blood cells count', 'Age']\n",
        "    minmax_scaler = MinMaxScaler()\n",
        "    print('Normalize count columns using MinMaxScaler')\n",
        "\n",
        "    # Fit on the training data and transform both training and testing data\n",
        "    X_train_normalized = X_train.copy()\n",
        "    X_train_normalized[count_columns] = minmax_scaler.fit_transform(X_train[count_columns])\n",
        "    print('Fit on the training data and transform both training and testing data')\n",
        "\n",
        "    X_test_normalized = X_test.copy()\n",
        "    X_test_normalized[count_columns] = minmax_scaler.transform(X_test[count_columns])\n",
        "    print('Done preprocessing Data')\n",
        "    return X_train_normalized, X_test_normalized,y_train,y_test\n",
        "\n",
        "# Usage\n",
        "# Assuming datasave is your original DataFrame\n",
        "X_train_normalized, X_test_normalized,y_train,y_test= prepare_data(datasave)\n",
        "print(\"Normalized X_train:\")\n",
        "print(X_train_normalized.head())\n",
        "\n",
        "print(\" y_train:\")\n",
        "print(y_train)\n",
        "\n",
        "print(\"\\nNormalized X_test:\")\n",
        "print(X_test_normalized.head())\n",
        "\n",
        "print(\"y_test:\")\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "zBFNacIfOBKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normalized"
      ],
      "metadata": {
        "id": "m-einnsw5NPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelling\n"
      ],
      "metadata": {
        "id": "YOu3gyshmVeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score,precision_score,recall_score,f1_score,confusion_matrix,roc_curve\n",
        "\n",
        "def run_classification_algorithm(algorithm, X_train, X_test, y_train, y_test):\n",
        "    if algorithm == 'LogisticRegression':\n",
        "        # Logistic Regression\n",
        "        model = LogisticRegression()\n",
        "        learnable_parameters = ['coef_', 'intercept_']\n",
        "        hyperparameters = {\n",
        "            'penalty': ['l1', 'l2'],\n",
        "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "            'fit_intercept': [True, False],\n",
        "            'solver': ['liblinear', 'saga'],\n",
        "            'max_iter': [100, 200, 300, 400, 500]\n",
        "        }\n",
        "        source_code = \"LogisticRegression()\"\n",
        "    elif algorithm == 'KNN':\n",
        "        # K-Nearest Neighbors\n",
        "        model = KNeighborsClassifier(n_neighbors=11)\n",
        "        learnable_parameters = ['_tree']\n",
        "        hyperparameters = {\n",
        "            'n_neighbors': [3, 5, 7, 9],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "            'p': [1, 2]\n",
        "        }\n",
        "        source_code = \"KNeighborsClassifier()\"\n",
        "    elif algorithm == 'DecisionTree':\n",
        "        # Decision Tree\n",
        "        model = DecisionTreeClassifier()\n",
        "        learnable_parameters = ['tree_']\n",
        "        hyperparameters = {\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'splitter': ['best', 'random'],\n",
        "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "        source_code = \"DecisionTreeClassifier()\"\n",
        "    elif algorithm == 'SVM':\n",
        "        # Support Vector Machine with RBF Kernel\n",
        "        model = SVC(kernel='rbf', probability=True)\n",
        "        learnable_parameters = ['dual_coef_', 'support_', 'n_support_']\n",
        "        hyperparameters = {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'gamma': ['scale', 'auto'],\n",
        "            'kernel': ['rbf']\n",
        "        }\n",
        "        source_code = \"SVC(kernel='rbf', probability=True)\"\n",
        "    elif algorithm == 'NaiveBayesGaussian':\n",
        "        # Gaussian Naive Bayes\n",
        "        model = GaussianNB()\n",
        "        learnable_parameters = ['theta_', 'sigma_']\n",
        "        hyperparameters = {}\n",
        "        source_code = \"GaussianNB()\"\n",
        "    elif algorithm == 'NaiveBayesBernoulli':\n",
        "        # Bernoulli Naive Bayes\n",
        "        model = BernoulliNB()\n",
        "        learnable_parameters = ['class_count_', 'feature_count_']\n",
        "        hyperparameters = {}\n",
        "        source_code = \"BernoulliNB()\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid algorithm name. Choose from: LogisticRegression, KNN, DecisionTree, SVM, NaiveBayesGaussian, NaiveBayesBernoulli\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "    auc_roc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    fpr,tpr,_=roc_curve(y_test, y_proba) if y_proba is not None else None\n",
        "\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "    # Results dictionary\n",
        "    results = {\n",
        "       'Modeling':{\n",
        "        'Algorithm': algorithm,\n",
        "        'LearnableParameters': learnable_parameters,\n",
        "        'HyperParameters': hyperparameters,\n",
        "        'SourceCode': source_code},\n",
        "        'Evaluation':{\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision':precision,\n",
        "        'Recall':recall,\n",
        "        'f1':f1,\n",
        "        'confusion_matrix':cnf_matrix,\n",
        "        'AUC-ROC': auc_roc,\n",
        "        'fpr':fpr,\n",
        "        'tpr':tpr,\n",
        "        'classification_rep':classification_rep}\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "resultsAll={}\n",
        "i=0\n",
        "algorithms_to_run = ['LogisticRegression', 'KNN', 'DecisionTree', 'SVM', 'NaiveBayesGaussian', 'NaiveBayesBernoulli']\n",
        "for algorithm in algorithms_to_run:\n",
        "    result= run_classification_algorithm(algorithm, X_train_normalized, X_test_normalized, y_train, y_test)\n",
        "    resultsAll[i]=result\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "x0r8bTmpU9H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key,value in resultsAll.items():\n",
        "  for k,v in value['Modeling'].items():\n",
        "        print(k+':')\n",
        "        print(v)\n",
        "  print('------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "oDcLujdPgoIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation\n"
      ],
      "metadata": {
        "id": "NsIuKjicsfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key,value in resultsAll.items():\n",
        "  print(value['Modeling']['Algorithm'])\n",
        "  for k,v in value['Evaluation'].items():\n",
        "    if k!=\"confusion_matrix\" and k!='fpr' and k!='tpr':\n",
        "        print(k+':')\n",
        "        print(v)\n",
        "\n",
        "  %matplotlib inline\n",
        "  class_names=[0,1]\n",
        "  fig, ax = plt.subplots()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "  # create heatmap\n",
        "  sns.heatmap(pd.DataFrame(value['Evaluation']['confusion_matrix']), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "  ax.xaxis.set_label_position(\"top\")\n",
        "  plt.tight_layout()\n",
        "  plt.title('Confusion matrix for '+value['Modeling']['Algorithm'], y=1.1)\n",
        "  plt.ylabel('Actual label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.plot(value['Evaluation']['fpr'], value['Evaluation']['tpr'], label=value['Modeling']['Algorithm']+ '(AUC =' + str(value['Evaluation']['AUC-ROC'])+')')\n",
        "  plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title(f'ROC Curve - '+value['Modeling']['Algorithm'])\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "  print('-----------------------------------------------------------------------------------------')\n"
      ],
      "metadata": {
        "id": "FFIYwhcDsdhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***GridSearch best estimator SVM***\n",
        "\n"
      ],
      "metadata": {
        "id": "wg23H8ByromD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def grid_search_svm_rbf(X_train, y_train):\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
        "\n",
        "    # Create an SVM model with RBF kernel\n",
        "    svm_model = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "    # Initialize GridSearchCV\n",
        "    grid_search = GridSearchCV(svm_model, param_grid,scoring = 'f1', cv=9, n_jobs=1, refit=True, verbose=3)\n",
        "\n",
        "    # Perform grid search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "\n",
        "    return grid_search\n",
        "\n",
        "grid_search = grid_search_svm_rbf(X_train_normalized, y_train)\n",
        "\n",
        "print(grid_search)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaP45plNnGW0",
        "outputId": "e702da71-c396-41a7-8042-9a7de3d6fb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 9 folds for each of 16 candidates, totalling 144 fits\n",
            "[CV 1/9] END ....................C=0.1, gamma=1;, score=0.795 total time= 1.6min\n",
            "[CV 2/9] END ....................C=0.1, gamma=1;, score=0.799 total time= 1.6min\n",
            "[CV 3/9] END ....................C=0.1, gamma=1;, score=0.785 total time= 1.6min\n",
            "[CV 4/9] END ....................C=0.1, gamma=1;, score=0.789 total time= 1.5min\n",
            "[CV 5/9] END ....................C=0.1, gamma=1;, score=0.791 total time= 1.5min\n",
            "[CV 6/9] END ....................C=0.1, gamma=1;, score=0.793 total time= 1.6min\n",
            "[CV 7/9] END ....................C=0.1, gamma=1;, score=0.794 total time= 1.5min\n",
            "[CV 8/9] END ....................C=0.1, gamma=1;, score=0.795 total time= 1.4min\n",
            "[CV 9/9] END ....................C=0.1, gamma=1;, score=0.794 total time= 1.4min\n",
            "[CV 1/9] END ..................C=0.1, gamma=0.1;, score=0.783 total time= 1.3min\n",
            "[CV 2/9] END ..................C=0.1, gamma=0.1;, score=0.784 total time= 1.4min\n",
            "[CV 3/9] END ..................C=0.1, gamma=0.1;, score=0.780 total time= 1.3min\n",
            "[CV 4/9] END ..................C=0.1, gamma=0.1;, score=0.785 total time= 1.3min\n",
            "[CV 5/9] END ..................C=0.1, gamma=0.1;, score=0.780 total time= 1.4min\n",
            "[CV 6/9] END ..................C=0.1, gamma=0.1;, score=0.788 total time= 1.3min\n",
            "[CV 7/9] END ..................C=0.1, gamma=0.1;, score=0.784 total time= 1.3min\n",
            "[CV 8/9] END ..................C=0.1, gamma=0.1;, score=0.787 total time= 1.4min\n",
            "[CV 9/9] END ..................C=0.1, gamma=0.1;, score=0.783 total time= 1.4min\n",
            "[CV 1/9] END .................C=0.1, gamma=0.01;, score=0.778 total time= 1.4min\n",
            "[CV 2/9] END .................C=0.1, gamma=0.01;, score=0.778 total time= 1.4min\n",
            "[CV 3/9] END .................C=0.1, gamma=0.01;, score=0.778 total time= 1.4min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_svm_model.predict(X_test_normalized)\n",
        "y_proba = best_svm_model.predict_proba(X_test_normalized)[:, 1] if hasattr(best_svm_model, 'predict_proba') else None\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "\n",
        "\n",
        "# Print evaluation metrics\n",
        "print('best hyperparameters')\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(auc_roc)\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n"
      ],
      "metadata": {
        "id": "TJwIpNe647Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "%matplotlib inline\n",
        "class_names=[0,1]\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_pred)), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "OqfL-Meb4KS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_svm_rbf(X_train_normalized, y_train, X_test_normalized, y_test, C=0.1, gamma=1):\n",
        "    # Create SVM with RBF kernel model\n",
        "    svm_rbf = SVC(kernel='rbf', probability=True, random_state=42, C=C, gamma=gamma)\n",
        "    print(svm_rbf)\n",
        "\n",
        "    # Fit the SVM model on the training data\n",
        "    svm_rbf.fit(X_train_normalized, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_svm_rbf = svm_rbf.predict(X_test_normalized)\n",
        "    y_proba = svm_rbf.predict_proba(X_test_normalized)[:, 1] if hasattr(svm_rbf, 'predict_proba') else None\n",
        "\n",
        "    # Evaluate the SVM with RBF kernel model\n",
        "    report_svm_rbf = classification_report(y_test, y_pred_svm_rbf)\n",
        "    accuracy = accuracy_score(y_test, y_pred_svm_rbf)\n",
        "    auc_roc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    precision = precision_score(y_test, y_pred_svm_rbf)\n",
        "    recall = recall_score(y_test, y_pred_svm_rbf)\n",
        "    f1 = f1_score(y_test, y_pred_svm_rbf)\n",
        "    cnf_matrix = confusion_matrix(y_test, y_pred_svm_rbf)\n",
        "\n",
        "    print(\"Results for SVM with RBF Kernel:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"f1: {f1:.4f}\")\n",
        "    print(f\"auc_roc: {auc_roc:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report_svm_rbf)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    class_names = [0, 1]  # name of classes\n",
        "    fig, ax = plt.subplots()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    # create heatmap\n",
        "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
        "    ax.xaxis.set_label_position(\"top\")\n",
        "    plt.tight_layout()\n",
        "    plt.title('Confusion matrix', y=1.1)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "    return svm_rbf\n",
        "\n",
        "svm_rbf=evaluate_svm_rbf(X_train_normalized, y_train, X_test_normalized, y_test, C=0.1, gamma=1)\n"
      ],
      "metadata": {
        "id": "NGKGARCL4a83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_naive_bayes(X_train_normalized, y_train, X_test_normalized, y_test, model_type='bernoulli'):\n",
        "    if model_type == 'gaussian':\n",
        "        model = GaussianNB()\n",
        "    elif model_type == 'bernoulli':\n",
        "        model = BernoulliNB()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model_type. Use 'gaussian' or 'bernoulli'.\")\n",
        "\n",
        "    # Fit the Naive Bayes model on the training data\n",
        "    model.fit(X_train_normalized, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test_normalized)\n",
        "    y_proba = model.predict_proba(X_test_normalized)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Evaluate the Naive Bayes model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    auc_roc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Results for {model_type.capitalize()} Naive Bayes:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"f1: {f1:.4f}\")\n",
        "    print(f\"auc_roc: {auc_roc:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    class_names = [0, 1]\n",
        "    fig, ax = plt.subplots()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    # create heatmap\n",
        "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
        "    ax.xaxis.set_label_position(\"top\")\n",
        "    plt.tight_layout()\n",
        "    plt.title(f'Confusion matrix ({model_type.capitalize()})', y=1.1)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "gnb_model = train_evaluate_naive_bayes(X_train_normalized, y_train, X_test_normalized, y_test, model_type='gaussian')\n",
        "bnb_model = train_evaluate_naive_bayes(X_train_normalized, y_train, X_test_normalized, y_test, model_type='bernoulli')\n"
      ],
      "metadata": {
        "id": "gryXz3hffpk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensemble Learning**"
      ],
      "metadata": {
        "id": "6Nl8xLSjrRnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def train_evaluate_voting_classifier(base_learners, X_train_normalized, y_train, X_test_normalized, y_test):\n",
        "    ensemble_learner = VotingClassifier(base_learners, voting='soft')\n",
        "    ensemble_learner.fit(X_train_normalized, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_ens = ensemble_learner.predict(X_test_normalized)\n",
        "    y_proba = ensemble_learner.predict_proba(X_test_normalized)[:, 1] if hasattr(ensemble_learner, 'predict_proba') else None\n",
        "\n",
        "    # Evaluate the VotingClassifier\n",
        "    print('Results for Ensemble (Voting Classifier):')\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_ens):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred_ens):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred_ens):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred_ens):.4f}\")\n",
        "    auc_roc_ensemble = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    print(f\"AUC-ROC: {auc_roc_ensemble:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cnf_matrix = confusion_matrix(y_test, y_pred_ens)\n",
        "    print(f\"Confusion Matrix:\\n{cnf_matrix}\\n\")\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    %matplotlib inline\n",
        "    class_names = [0, 1]  # name of classes\n",
        "    fig, ax = plt.subplots()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    # create heatmap\n",
        "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
        "    ax.xaxis.set_label_position(\"top\")\n",
        "    plt.tight_layout()\n",
        "    plt.title('Confusion matrix (Ensemble)', y=1.1)\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "    return ensemble_learner\n",
        "\n",
        "ensemble_learners = [('SVM', svm_rbf), ('BernoulliNB', bnb_model)]\n",
        "voting_classifier_model = train_evaluate_voting_classifier(ensemble_learners, X_train_normalized, y_train, X_test_normalized, y_test)\n"
      ],
      "metadata": {
        "id": "lJK5YSz-YE1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}